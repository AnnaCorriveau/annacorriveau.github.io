---
title: "Functional brain networks predicting sustained attention are not specific to perceptual modality"
collection: publications
permalink: /publication/3/20/25-Functional brain networks predicting sustained attention are not specific to perceptual modality
excerpt: 'Sustained attention is essential for daily life and can be directed to information from different perceptual modalities, including audition and vision. Prior work has shown strong generalization of models trained to predict individual differences in sustained attention performance from patterns of fMRI functional connectivity. However, it is an open question whether predictions of sustained attention are specific to the perceptual modality in which they are trained. We find that functional networks are largely modality general, with both model-unique and shared model features predicting sustained attention performance in independent datasets regardless of task modality. Results support the supposition that visual and auditory sustained attention rely on shared neural mechanisms and demonstrate robust generalizability of whole-brain functional network models of sustained attention.'
date: 3/20/25
venue: 'Network Neuroscience'
paperurl: 'http://annacorriveau.github.io/files/netn_a_00430.pdf'
citation: 'Corriveau, A., Ke, J., Terashima, H., Kondo, H. M., &amp; Rosenberg, M. D. (2025). Functional brain networks predicting sustained attention are not specific to perceptual modality. Network Neuroscience, 9(1), 303â€“325. https://doi.org/10.1162/netn_a_00430'
---

<a href='http://annacorriveau.github.io/files/netn_a_00430.pdf'>Download paper here</a>

<a href='https://direct.mit.edu/netn/article/9/1/303/125503/Functional-brain-networks-predicting-sustained'>Read paper online here</a>

Sustained attention is essential for daily life and can be directed to information from different perceptual modalities, including audition and vision. Prior work has shown strong generalization of models trained to predict individual differences in sustained attention performance from patterns of fMRI functional connectivity. However, it is an open question whether predictions of sustained attention are specific to the perceptual modality in which they are trained. We find that functional networks are largely modality general, with both model-unique and shared model features predicting sustained attention performance in independent datasets regardless of task modality. Results support the supposition that visual and auditory sustained attention rely on shared neural mechanisms and demonstrate robust generalizability of whole-brain functional network models of sustained attention.
